{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from patchify import patchify, unpatchify\n",
    "import seaborn as sns\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler,ReduceLROnPlateau\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, BatchNormalization, Activation, Flatten, Dense, Input, MaxPooling2D, Add, Reshape, concatenate, AveragePooling2D, Multiply, GlobalAveragePooling2D, UpSampling2D, MaxPool2D,Softmax\n",
    "from tensorflow.keras.activations import softmax\n",
    "from tensorflow.keras import initializers, regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patches(img, patch_size):\n",
    "    patches = patchify(img, (patch_size, patch_size, 3), step=patch_size)\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom function to get denoised image prediction for noisy images\n",
    "def prediction(img,model):\n",
    "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "  img = cv2.resize(img,(1024,1024))\n",
    "  img = img.astype(\"float32\") / 255.0\n",
    "\n",
    "  img_patches = patches(img,256)\n",
    "\n",
    "  nsy=[]\n",
    "  for i in range(4):\n",
    "    for j in range(4):\n",
    "      nsy.append(img_patches[i][j][0])\n",
    "  nsy = np.array(nsy)\n",
    "\n",
    "  pred_img = model.predict(nsy)\n",
    "  pred_img = np.reshape(pred_img,(4,4,1,256,256,3))\n",
    "  pred_img = unpatchify(pred_img, img.shape)\n",
    "  return pred_img\n",
    "\n",
    "\n",
    "#Custom function to get denoised image prediction for noisy images on quantized models using tflite\n",
    "def prediction_tflite(img,model):\n",
    "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "  img = cv2.resize(img,(1024,1024))\n",
    "  img = img.astype(\"float32\") / 255.0\n",
    "\n",
    "  img_patches = patches(img,256)\n",
    "\n",
    "  nsy=[]\n",
    "  for i in range(4):\n",
    "    for j in range(4):\n",
    "      nsy.append(img_patches[i][j][0])\n",
    "  nsy = np.array(nsy)\n",
    "  pred=[]\n",
    "  for patch in nsy:\n",
    "    model.set_tensor(input_details[0]['index'], tf.expand_dims(patch,axis=0))\n",
    "    model.invoke()\n",
    "    tflite_model_predictions = model.get_tensor(output_details[0]['index'])\n",
    "    pred.append(tflite_model_predictions)\n",
    "\n",
    "  pred_img = np.reshape(pred,(4,4,1,256,256,3))\n",
    "  pred_img = unpatchify(pred_img, img.shape)\n",
    "  return pred_img\n",
    "\n",
    "#Custom function to plot/visualize noisy, ground truth and predicted images\n",
    "def visualize(sample,model):\n",
    "  fig,ax = plt.subplots(len(sample),3,figsize=(30,30))\n",
    "  for i in range(len(sample)):\n",
    "    path = sample['Ground Truth Images'].iloc[i]\n",
    "    test_img_gt = cv2.imread(path)\n",
    "    test_img_gt = cv2.cvtColor(test_img_gt, cv2.COLOR_BGR2RGB)\n",
    "    test_img_gt = cv2.resize(test_img_gt,(512,512))\n",
    "    test_img_gt = test_img_gt.astype(\"float32\") / 255.0\n",
    "  \n",
    "    path = sample['Noisy Images'].iloc[i]\n",
    "    test_img_nsy = cv2.imread(path)\n",
    "    pred_img = prediction(test_img_nsy,model)\n",
    "    pred_img = cv2.resize(pred_img,(512,512))\n",
    "\n",
    "    test_img_nsy = cv2.cvtColor(test_img_nsy, cv2.COLOR_BGR2RGB)\n",
    "    test_img_nsy = cv2.resize(test_img_nsy,(512,512))\n",
    "    test_img_nsy = test_img_nsy.astype(\"float32\") / 255.0\n",
    "    \n",
    "    ax[i][0].imshow(test_img_nsy)\n",
    "    ax[i][0].get_xaxis().set_visible(False)\n",
    "    ax[i][0].get_yaxis().set_visible(False)\n",
    "    ax[i][0].title.set_text(\"Noisy Image\")\n",
    "\n",
    "    ax[i][1].imshow(test_img_gt)\n",
    "    ax[i][1].get_xaxis().set_visible(False)\n",
    "    ax[i][1].get_yaxis().set_visible(False)\n",
    "    ax[i][1].title.set_text(\"Ground Truth Image\")\n",
    "\n",
    "    ax[i][2].imshow(pred_img)\n",
    "    ax[i][2].get_xaxis().set_visible(False)\n",
    "    ax[i][2].get_yaxis().set_visible(False)\n",
    "    ax[i][2].title.set_text(\"Predicted Image\")\n",
    "\n",
    "#Custom function that computes the psnr and ssim values for images\n",
    "def psnr_and_ssim(X_test,y_test,model,model_type='Normal'):\n",
    "  psnr_nsy = 0.0\n",
    "  psnr_de_nsy = 0.0\n",
    "  ssim_nsy = 0.0\n",
    "  ssim_de_nsy = 0.0\n",
    "  for i in range(len(X_test)):\n",
    "    #getting the noisy images\n",
    "    path = X_test.iloc[i]\n",
    "    nsy = cv2.imread(path)  \n",
    "\n",
    "    #getting the predicted images\n",
    "    if model_type == 'Quantized': \n",
    "      pred = prediction_tflite(nsy,model)\n",
    "    else:\n",
    "      pred = prediction(nsy,model)\n",
    "\n",
    "    #getting the ground truth images\n",
    "    path = y_test.iloc[i]\n",
    "    gt = cv2.imread(path)         \n",
    "    gt = cv2.cvtColor(gt, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    #Resizing the images\n",
    "    gt = cv2.resize(gt,(1024,1024))\n",
    "    nsy = cv2.resize(nsy,(1024,1024))\n",
    "\n",
    "    #Normalizing the images\n",
    "    gt = gt.astype(\"float32\") / 255.0\n",
    "    nsy = nsy.astype(\"float32\") / 255.0\n",
    "\n",
    "    #Computing psnr and ssim for test images\n",
    "    psnr_nsy += psnr(gt,nsy)\n",
    "    psnr_de_nsy += psnr(gt,pred)\n",
    "    ssim_nsy += ssim(gt,nsy,multichannel=True,data_range=nsy.max() - nsy.min())\n",
    "    ssim_de_nsy += ssim(gt,pred,multichannel=True,data_range=pred.max() - pred.min())\n",
    "\n",
    "  psnr_nsy = psnr_nsy/len(X_test)\n",
    "  psnr_de_nsy = psnr_de_nsy/len(X_test)\n",
    "  ssim_nsy = ssim_nsy/len(X_test)\n",
    "  ssim_de_nsy = ssim_de_nsy/len(X_test)\n",
    "  return psnr_nsy, psnr_de_nsy,ssim_nsy,ssim_de_nsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_patches, y_train_patches = pickle.load(open('train_data.pkl', 'rb'))\n",
    "X_test_patches,y_test_patches = pickle.load(open('test_data.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 256, 256, 3)\n",
      "(4096, 256, 256, 3)\n",
      "(1024, 256, 256, 3)\n",
      "(1024, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_patches.shape)\n",
    "print(y_train_patches.shape)\n",
    "print(X_test_patches.shape)\n",
    "print(y_test_patches.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the image pixels\n",
    "X_train_patches = X_train_patches.astype('float32') / 255.0\n",
    "y_train_patches = y_train_patches.astype('float32') / 255.0\n",
    "X_test_patches = X_test_patches.astype('float32') / 255.0\n",
    "y_test_patches = y_test_patches.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloader(tf.keras.utils.Sequence):\n",
    "    def __init__(self, X, y, batch_size=1, shuffle=False):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(X))\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        batch_x = self.X[i * self.batch_size : (i + 1) * self.batch_size]\n",
    "        batch_y= self.y[i * self.batch_size : (i + 1) * self.batch_size]\n",
    "        return tuple((batch_x, batch_y))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indexes)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.indexes = np.random.permutation(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dataloader = Dataloader(X_train_patches,y_train_patches, batch_size, shuffle=True)\n",
    "test_dataloader = Dataloader(X_test_patches,y_test_patches,batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 256, 256, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 256, 56, 3)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 256, 56, 32)  896         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 256, 56, 32)  9248        ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 256, 56, 32)  9248        ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 256, 56, 32)  9248        ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 256, 56, 3)   867         ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 256, 56, 6)   0           ['conv2d_4[0][0]',               \n",
      "                                                                  'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 256, 56, 64)  3520        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 256, 56, 64)  36928       ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 128, 28, 64)  0          ['conv2d_6[0][0]']               \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 128, 28, 128  73856       ['average_pooling2d[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 128, 28, 128  147584      ['conv2d_7[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 128, 28, 128  147584      ['conv2d_8[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 64, 14, 128)  0          ['conv2d_9[0][0]']               \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 64, 14, 256)  295168      ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 64, 14, 256)  590080      ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 64, 14, 256)  590080      ['conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 64, 14, 256)  590080      ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 64, 14, 256)  590080      ['conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 64, 14, 256)  590080      ['conv2d_14[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 128, 28, 128  295040     ['conv2d_15[0][0]']              \n",
      " ose)                           )                                                                 \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 128, 28, 128  0           ['conv2d_transpose[0][0]',       \n",
      "                                )                                 'conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 128, 28, 128  147584      ['add[0][0]']                    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 128, 28, 128  147584      ['conv2d_16[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 128, 28, 128  147584      ['conv2d_17[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 256, 56, 64)  73792      ['conv2d_18[0][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 256, 56, 64)  0           ['conv2d_transpose_1[0][0]',     \n",
      "                                                                  'conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 256, 56, 64)  36928       ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 256, 56, 64)  36928       ['conv2d_19[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 256, 56, 3)   195         ['conv2d_20[0][0]']              \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 256, 56, 3)   0           ['conv2d_21[0][0]',              \n",
      "                                                                  'input_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,570,182\n",
      "Trainable params: 4,570,182\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "input = Input(shape=(256, 56, 3))\n",
    "\n",
    "# Noise estimation subnetwork\n",
    "x = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(input)\n",
    "x = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(x)\n",
    "x = Conv2D(3, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(x)\n",
    "\n",
    "# Non Blind denoising subnetwork\n",
    "x = concatenate([x, input])\n",
    "conv1 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(x)\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv1)\n",
    "\n",
    "pool1 = AveragePooling2D(pool_size=(2, 2), padding='same')(conv2)\n",
    "conv3 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(pool1)\n",
    "conv4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv3)\n",
    "conv5 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv4)\n",
    "\n",
    "pool2 = AveragePooling2D(pool_size=(2, 2), padding='same')(conv5)\n",
    "conv6 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(pool2)\n",
    "conv7 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv6)\n",
    "conv8 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv7)\n",
    "conv9 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv8)\n",
    "conv10 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv9)\n",
    "conv11 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv10)\n",
    "\n",
    "upsample1 = Conv2DTranspose(128, (3, 3), strides=2, activation=\"relu\", kernel_initializer='he_normal',padding=\"same\")(conv11)\n",
    "add1 = Add()([upsample1,conv5])\n",
    "conv12 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(add1)\n",
    "conv13 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv12)\n",
    "conv14 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv13)\n",
    "\n",
    "upsample2 = Conv2DTranspose(64, (3, 3), strides=2, activation=\"relu\", kernel_initializer='he_normal',padding=\"same\")(conv14)\n",
    "add1 = Add()([upsample2, conv2])\n",
    "conv15 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(add1)\n",
    "conv16 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv15)\n",
    "\n",
    "out = Conv2D(3, (1, 1), kernel_initializer='he_normal', padding='same')(conv16)\n",
    "out = Add()([out, input])\n",
    "\n",
    "CBDNet = Model(input, out)\n",
    "CBDNet.compile(optimizer=tf.keras.optimizers.Adam(1e-03), loss=tf.keras.losses.MeanSquaredError())\n",
    "CBDNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'model/add/add' defined at (most recent call last):\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 737, in start\n      self.io_loop.start()\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 524, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in process_one\n      await dispatch(*args)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 418, in dispatch_shell\n      await result\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 758, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 426, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Federico\\AppData\\Local\\Temp\\ipykernel_16756\\3568004502.py\", line 6, in <module>\n      CBDNet.fit(train_dataloader,shuffle=True,epochs=30,validation_data= test_dataloader,callbacks=callback)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\layers\\merging\\base_merge.py\", line 196, in call\n      return self._merge_function(inputs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\layers\\merging\\add.py\", line 57, in _merge_function\n      output += inputs[i]\nNode: 'model/add/add'\nrequired broadcastable shapes\n\t [[{{node model/add/add}}]] [Op:__inference_train_function_2853]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Federico\\Documents\\Sviluppo\\Git\\PathTracing\\CNN-Denoiser\\CBDNet.ipynb Cella 11\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Federico/Documents/Sviluppo/Git/PathTracing/CNN-Denoiser/CBDNet.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m reducelr \u001b[39m=\u001b[39m ReduceLROnPlateau(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, factor\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m,verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,patience\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m,min_delta\u001b[39m=\u001b[39m\u001b[39m0.00001\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Federico/Documents/Sviluppo/Git/PathTracing/CNN-Denoiser/CBDNet.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m callback \u001b[39m=\u001b[39m [tensorboard,reducelr]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Federico/Documents/Sviluppo/Git/PathTracing/CNN-Denoiser/CBDNet.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m CBDNet\u001b[39m.\u001b[39;49mfit(train_dataloader,shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,epochs\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m,validation_data\u001b[39m=\u001b[39;49m test_dataloader,callbacks\u001b[39m=\u001b[39;49mcallback)\n",
      "File \u001b[1;32mc:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'model/add/add' defined at (most recent call last):\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 737, in start\n      self.io_loop.start()\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 524, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in process_one\n      await dispatch(*args)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 418, in dispatch_shell\n      await result\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 758, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 426, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Federico\\AppData\\Local\\Temp\\ipykernel_16756\\3568004502.py\", line 6, in <module>\n      CBDNet.fit(train_dataloader,shuffle=True,epochs=30,validation_data= test_dataloader,callbacks=callback)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\layers\\merging\\base_merge.py\", line 196, in call\n      return self._merge_function(inputs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\layers\\merging\\add.py\", line 57, in _merge_function\n      output += inputs[i]\nNode: 'model/add/add'\nrequired broadcastable shapes\n\t [[{{node model/add/add}}]] [Op:__inference_train_function_2853]"
     ]
    }
   ],
   "source": [
    "log_dir=\"logs/cbdnet\"\n",
    "\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1, write_graph=True,write_grads=True)\n",
    "reducelr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,verbose=1,patience=4,min_delta=0.00001)\n",
    "callback = [tensorboard,reducelr]\n",
    "CBDNet.fit(train_dataloader,shuffle=True,epochs=30,validation_data= test_dataloader,callbacks=callback)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
