{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from patchify import patchify, unpatchify\n",
    "import seaborn as sns\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler,ReduceLROnPlateau\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, BatchNormalization, Activation, Flatten, Dense, Input, MaxPooling2D, Add, Reshape, concatenate, AveragePooling2D, Multiply, GlobalAveragePooling2D, UpSampling2D, MaxPool2D,Softmax\n",
    "from tensorflow.keras.activations import softmax\n",
    "from tensorflow.keras import initializers, regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patches(img, patch_size):\n",
    "    patches = patchify(img, (patch_size, patch_size, 3), step=patch_size)\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom function to get denoised image prediction for noisy images\n",
    "def prediction(img,model):\n",
    "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "  img = cv2.resize(img,(1024,1024))\n",
    "  img = img.astype(\"float32\") / 255.0\n",
    "\n",
    "  img_patches = patches(img,256)\n",
    "\n",
    "  nsy=[]\n",
    "  for i in range(4):\n",
    "    for j in range(4):\n",
    "      nsy.append(img_patches[i][j][0])\n",
    "  nsy = np.array(nsy)\n",
    "\n",
    "  pred_img = model.predict(nsy)\n",
    "  pred_img = np.reshape(pred_img,(4,4,1,256,256,3))\n",
    "  pred_img = unpatchify(pred_img, img.shape)\n",
    "  return pred_img\n",
    "\n",
    "\n",
    "#Custom function to get denoised image prediction for noisy images on quantized models using tflite\n",
    "def prediction_tflite(img,model):\n",
    "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "  img = cv2.resize(img,(1024,1024))\n",
    "  img = img.astype(\"float32\") / 255.0\n",
    "\n",
    "  img_patches = patches(img,256)\n",
    "\n",
    "  nsy=[]\n",
    "  for i in range(4):\n",
    "    for j in range(4):\n",
    "      nsy.append(img_patches[i][j][0])\n",
    "  nsy = np.array(nsy)\n",
    "  pred=[]\n",
    "  for patch in nsy:\n",
    "    model.set_tensor(input_details[0]['index'], tf.expand_dims(patch,axis=0))\n",
    "    model.invoke()\n",
    "    tflite_model_predictions = model.get_tensor(output_details[0]['index'])\n",
    "    pred.append(tflite_model_predictions)\n",
    "\n",
    "  pred_img = np.reshape(pred,(4,4,1,256,256,3))\n",
    "  pred_img = unpatchify(pred_img, img.shape)\n",
    "  return pred_img\n",
    "\n",
    "#Custom function to plot/visualize noisy, ground truth and predicted images\n",
    "def visualize(sample,model):\n",
    "  fig,ax = plt.subplots(len(sample),3,figsize=(30,30))\n",
    "  for i in range(len(sample)):\n",
    "    path = sample['Ground Truth Images'].iloc[i]\n",
    "    test_img_gt = cv2.imread(path)\n",
    "    test_img_gt = cv2.cvtColor(test_img_gt, cv2.COLOR_BGR2RGB)\n",
    "    test_img_gt = cv2.resize(test_img_gt,(512,512))\n",
    "    test_img_gt = test_img_gt.astype(\"float32\") / 255.0\n",
    "  \n",
    "    path = sample['Noisy Images'].iloc[i]\n",
    "    test_img_nsy = cv2.imread(path)\n",
    "    pred_img = prediction(test_img_nsy,model)\n",
    "    pred_img = cv2.resize(pred_img,(512,512))\n",
    "\n",
    "    test_img_nsy = cv2.cvtColor(test_img_nsy, cv2.COLOR_BGR2RGB)\n",
    "    test_img_nsy = cv2.resize(test_img_nsy,(512,512))\n",
    "    test_img_nsy = test_img_nsy.astype(\"float32\") / 255.0\n",
    "    \n",
    "    ax[i][0].imshow(test_img_nsy)\n",
    "    ax[i][0].get_xaxis().set_visible(False)\n",
    "    ax[i][0].get_yaxis().set_visible(False)\n",
    "    ax[i][0].title.set_text(\"Noisy Image\")\n",
    "\n",
    "    ax[i][1].imshow(test_img_gt)\n",
    "    ax[i][1].get_xaxis().set_visible(False)\n",
    "    ax[i][1].get_yaxis().set_visible(False)\n",
    "    ax[i][1].title.set_text(\"Ground Truth Image\")\n",
    "\n",
    "    ax[i][2].imshow(pred_img)\n",
    "    ax[i][2].get_xaxis().set_visible(False)\n",
    "    ax[i][2].get_yaxis().set_visible(False)\n",
    "    ax[i][2].title.set_text(\"Predicted Image\")\n",
    "\n",
    "#Custom function that computes the psnr and ssim values for images\n",
    "def psnr_and_ssim(X_test,y_test,model,model_type='Normal'):\n",
    "  psnr_nsy = 0.0\n",
    "  psnr_de_nsy = 0.0\n",
    "  ssim_nsy = 0.0\n",
    "  ssim_de_nsy = 0.0\n",
    "  for i in range(len(X_test)):\n",
    "    #getting the noisy images\n",
    "    path = X_test.iloc[i]\n",
    "    nsy = cv2.imread(path)  \n",
    "\n",
    "    #getting the predicted images\n",
    "    if model_type == 'Quantized': \n",
    "      pred = prediction_tflite(nsy,model)\n",
    "    else:\n",
    "      pred = prediction(nsy,model)\n",
    "\n",
    "    #getting the ground truth images\n",
    "    path = y_test.iloc[i]\n",
    "    gt = cv2.imread(path)         \n",
    "    gt = cv2.cvtColor(gt, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    #Resizing the images\n",
    "    gt = cv2.resize(gt,(1024,1024))\n",
    "    nsy = cv2.resize(nsy,(1024,1024))\n",
    "\n",
    "    #Normalizing the images\n",
    "    gt = gt.astype(\"float32\") / 255.0\n",
    "    nsy = nsy.astype(\"float32\") / 255.0\n",
    "\n",
    "    #Computing psnr and ssim for test images\n",
    "    psnr_nsy += psnr(gt,nsy)\n",
    "    psnr_de_nsy += psnr(gt,pred)\n",
    "    ssim_nsy += ssim(gt,nsy,multichannel=True,data_range=nsy.max() - nsy.min())\n",
    "    ssim_de_nsy += ssim(gt,pred,multichannel=True,data_range=pred.max() - pred.min())\n",
    "\n",
    "  psnr_nsy = psnr_nsy/len(X_test)\n",
    "  psnr_de_nsy = psnr_de_nsy/len(X_test)\n",
    "  ssim_nsy = ssim_nsy/len(X_test)\n",
    "  ssim_de_nsy = ssim_de_nsy/len(X_test)\n",
    "  return psnr_nsy, psnr_de_nsy,ssim_nsy,ssim_de_nsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_patches, y_train_patches = pickle.load(open('train_data.pkl', 'rb'))\n",
    "X_test_patches,y_test_patches = pickle.load(open('test_data.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 256, 256, 3)\n",
      "(4096, 256, 256, 3)\n",
      "(1024, 256, 256, 3)\n",
      "(1024, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_patches.shape)\n",
    "print(y_train_patches.shape)\n",
    "print(X_test_patches.shape)\n",
    "print(y_test_patches.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the image pixels\n",
    "X_train_patches = X_train_patches.astype('float32') / 255.0\n",
    "y_train_patches = y_train_patches.astype('float32') / 255.0\n",
    "X_test_patches = X_test_patches.astype('float32') / 255.0\n",
    "y_test_patches = y_test_patches.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloader(tf.keras.utils.Sequence):\n",
    "    def __init__(self, X, y, batch_size=1, shuffle=False):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(X))\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        batch_x = self.X[i * self.batch_size : (i + 1) * self.batch_size]\n",
    "        batch_y= self.y[i * self.batch_size : (i + 1) * self.batch_size]\n",
    "        return tuple((batch_x, batch_y))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indexes)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.indexes = np.random.permutation(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dataloader = Dataloader(X_train_patches,y_train_patches, batch_size, shuffle=True)\n",
    "test_dataloader = Dataloader(X_test_patches,y_test_patches,batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 256, 256, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 256, 256, 32  896         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 256, 256, 32  9248        ['conv2d[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 256, 256, 32  9248        ['conv2d_1[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 256, 256, 32  9248        ['conv2d_2[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 256, 256, 3)  867         ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 256, 256, 6)  0           ['conv2d_4[0][0]',               \n",
      "                                                                  'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 256, 256, 64  3520        ['concatenate[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 256, 256, 64  36928       ['conv2d_5[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 128, 128, 64  0          ['conv2d_6[0][0]']               \n",
      " ing2D)                         )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 128, 128, 12  73856       ['average_pooling2d[0][0]']      \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 128, 128, 12  147584      ['conv2d_7[0][0]']               \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 128, 128, 12  147584      ['conv2d_8[0][0]']               \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 64, 64, 128)  0          ['conv2d_9[0][0]']               \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 64, 64, 256)  295168      ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 64, 64, 256)  590080      ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 64, 64, 256)  590080      ['conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 64, 64, 256)  590080      ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 64, 64, 256)  590080      ['conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 64, 64, 256)  590080      ['conv2d_14[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 128, 128, 12  295040     ['conv2d_15[0][0]']              \n",
      " ose)                           8)                                                                \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 128, 128, 12  0           ['conv2d_transpose[0][0]',       \n",
      "                                8)                                'conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 128, 128, 12  147584      ['add[0][0]']                    \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 128, 128, 12  147584      ['conv2d_16[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 128, 128, 12  147584      ['conv2d_17[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 256, 256, 64  73792      ['conv2d_18[0][0]']              \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 256, 256, 64  0           ['conv2d_transpose_1[0][0]',     \n",
      "                                )                                 'conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 256, 256, 64  36928       ['add_1[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 256, 256, 64  36928       ['conv2d_19[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 256, 256, 3)  195         ['conv2d_20[0][0]']              \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 256, 256, 3)  0           ['conv2d_21[0][0]',              \n",
      "                                                                  'input_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,570,182\n",
      "Trainable params: 4,570,182\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "input = Input(shape=(256, 256, 3))\n",
    "\n",
    "# Noise estimation subnetwork\n",
    "x = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(input)\n",
    "x = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(x)\n",
    "x = Conv2D(3, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(x)\n",
    "\n",
    "# Non Blind denoising subnetwork\n",
    "x = concatenate([x, input])\n",
    "conv1 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(x)\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv1)\n",
    "\n",
    "pool1 = AveragePooling2D(pool_size=(2, 2), padding='same')(conv2)\n",
    "conv3 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(pool1)\n",
    "conv4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv3)\n",
    "conv5 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv4)\n",
    "\n",
    "pool2 = AveragePooling2D(pool_size=(2, 2), padding='same')(conv5)\n",
    "conv6 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(pool2)\n",
    "conv7 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv6)\n",
    "conv8 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv7)\n",
    "conv9 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv8)\n",
    "conv10 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv9)\n",
    "conv11 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv10)\n",
    "\n",
    "upsample1 = Conv2DTranspose(128, (3, 3), strides=2, activation=\"relu\", kernel_initializer='he_normal',padding=\"same\")(conv11)\n",
    "add1 = Add()([upsample1,conv5])\n",
    "conv12 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(add1)\n",
    "conv13 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv12)\n",
    "conv14 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv13)\n",
    "\n",
    "upsample2 = Conv2DTranspose(64, (3, 3), strides=2, activation=\"relu\", kernel_initializer='he_normal',padding=\"same\")(conv14)\n",
    "add1 = Add()([upsample2, conv2])\n",
    "conv15 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(add1)\n",
    "conv16 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv15)\n",
    "\n",
    "out = Conv2D(3, (1, 1), kernel_initializer='he_normal', padding='same')(conv16)\n",
    "out = Add()([out, input])\n",
    "\n",
    "CBDNet = Model(input, out)\n",
    "CBDNet.compile(optimizer=tf.keras.optimizers.Adam(1e-03), loss=tf.keras.losses.MeanSquaredError())\n",
    "CBDNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n",
      "Epoch 1/30\n",
      "4096/4096 [==============================] - 128s 31ms/step - loss: 67957304590336.0000 - val_loss: 0.0027 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "4096/4096 [==============================] - 108s 26ms/step - loss: 2.7074e-05 - val_loss: 0.0027 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "4096/4096 [==============================] - 109s 27ms/step - loss: 2.7074e-05 - val_loss: 0.0027 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "4096/4096 [==============================] - 108s 26ms/step - loss: 2.7074e-05 - val_loss: 0.0027 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "4089/4096 [============================>.] - ETA: 0s - loss: 2.7073e-05\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "4096/4096 [==============================] - 108s 26ms/step - loss: 2.7073e-05 - val_loss: 0.0027 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "4096/4096 [==============================] - 108s 26ms/step - loss: 2.7069e-05 - val_loss: 0.0027 - lr: 1.0000e-04\n",
      "Epoch 7/30\n",
      "4096/4096 [==============================] - 108s 26ms/step - loss: 2.7055e-05 - val_loss: 0.0027 - lr: 1.0000e-04\n",
      "Epoch 8/30\n",
      "4096/4096 [==============================] - 107s 26ms/step - loss: 2.6940e-05 - val_loss: 0.0027 - lr: 1.0000e-04\n",
      "Epoch 9/30\n",
      "4072/4096 [============================>.] - ETA: 0s - loss: 2.6110e-05\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "4096/4096 [==============================] - 105s 26ms/step - loss: 2.6110e-05 - val_loss: 0.0027 - lr: 1.0000e-04\n",
      "Epoch 10/30\n",
      "4096/4096 [==============================] - 105s 26ms/step - loss: 2.4399e-05 - val_loss: 0.0027 - lr: 1.0000e-05\n",
      "Epoch 11/30\n",
      "4096/4096 [==============================] - 105s 26ms/step - loss: 2.0378e-05 - val_loss: 0.0027 - lr: 1.0000e-05\n",
      "Epoch 12/30\n",
      "4096/4096 [==============================] - 105s 26ms/step - loss: 7.8926e-06 - val_loss: 0.0027 - lr: 1.0000e-05\n",
      "Epoch 13/30\n",
      "4096/4096 [==============================] - 105s 26ms/step - loss: 3.7035e-07 - val_loss: 0.0026 - lr: 1.0000e-05\n",
      "Epoch 14/30\n",
      "4096/4096 [==============================] - 104s 26ms/step - loss: 6.7313e-12 - val_loss: 0.0026 - lr: 1.0000e-05\n",
      "Epoch 15/30\n",
      "4096/4096 [==============================] - 105s 26ms/step - loss: 8.4986e-11 - val_loss: 0.0026 - lr: 1.0000e-05\n",
      "Epoch 16/30\n",
      "4096/4096 [==============================] - 105s 26ms/step - loss: 4.0769e-10 - val_loss: 0.0026 - lr: 1.0000e-05\n",
      "Epoch 17/30\n",
      "4095/4096 [============================>.] - ETA: 0s - loss: 3.4528e-10\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "4096/4096 [==============================] - 103s 25ms/step - loss: 3.4528e-10 - val_loss: 0.0026 - lr: 1.0000e-05\n",
      "Epoch 18/30\n",
      "4096/4096 [==============================] - 105s 26ms/step - loss: 1.2652e-12 - val_loss: 0.0026 - lr: 1.0000e-06\n",
      "Epoch 19/30\n",
      "4096/4096 [==============================] - 105s 26ms/step - loss: 2.6251e-12 - val_loss: 0.0026 - lr: 1.0000e-06\n",
      "Epoch 20/30\n",
      "4096/4096 [==============================] - 104s 25ms/step - loss: 2.1403e-12 - val_loss: 0.0026 - lr: 1.0000e-06\n",
      "Epoch 21/30\n",
      "4094/4096 [============================>.] - ETA: 0s - loss: 3.1018e-12\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "4096/4096 [==============================] - 105s 26ms/step - loss: 3.1018e-12 - val_loss: 0.0026 - lr: 1.0000e-06\n",
      "Epoch 22/30\n",
      "4096/4096 [==============================] - 105s 26ms/step - loss: 1.0737e-12 - val_loss: 0.0026 - lr: 1.0000e-07\n",
      "Epoch 23/30\n",
      "4096/4096 [==============================] - 105s 26ms/step - loss: 1.0757e-12 - val_loss: 0.0026 - lr: 1.0000e-07\n",
      "Epoch 24/30\n",
      "4096/4096 [==============================] - 103s 25ms/step - loss: 1.0702e-12 - val_loss: 0.0026 - lr: 1.0000e-07\n",
      "Epoch 25/30\n",
      "4075/4096 [============================>.] - ETA: 0s - loss: 1.0724e-12\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "4096/4096 [==============================] - 103s 25ms/step - loss: 1.0724e-12 - val_loss: 0.0026 - lr: 1.0000e-07\n",
      "Epoch 26/30\n",
      "4096/4096 [==============================] - 103s 25ms/step - loss: 1.0670e-12 - val_loss: 0.0026 - lr: 1.0000e-08\n",
      "Epoch 27/30\n",
      "4096/4096 [==============================] - 103s 25ms/step - loss: 1.0696e-12 - val_loss: 0.0026 - lr: 1.0000e-08\n",
      "Epoch 28/30\n",
      "4096/4096 [==============================] - 103s 25ms/step - loss: 1.0677e-12 - val_loss: 0.0026 - lr: 1.0000e-08\n",
      "Epoch 29/30\n",
      "4087/4096 [============================>.] - ETA: 0s - loss: 1.0696e-12\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "4096/4096 [==============================] - 103s 25ms/step - loss: 1.0696e-12 - val_loss: 0.0026 - lr: 1.0000e-08\n",
      "Epoch 30/30\n",
      "4096/4096 [==============================] - 103s 25ms/step - loss: 1.0731e-12 - val_loss: 0.0026 - lr: 1.0000e-09\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1530ae53d30>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_dir=\"logs/cbdnet\"\n",
    "\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1, write_graph=True,write_grads=True)\n",
    "reducelr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,verbose=1,patience=4,min_delta=0.00001)\n",
    "callback = [tensorboard,reducelr]\n",
    "CBDNet.fit(train_dataloader,shuffle=True,epochs=30,validation_data= test_dataloader,callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir \"/logs/cbdnet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 24). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/CBDNet\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/CBDNet\\assets\n"
     ]
    }
   ],
   "source": [
    "CBDNet.save('models/CBDNet', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CBDNet = tf.keras.models.load_model('models/CBDNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.DataFrame({'Ground Truth Images' : ['datasets/GT3.png'], 'Noisy Images' : ['datasets/N3.png']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model/conv2d_5/Relu' defined at (most recent call last):\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 737, in start\n      self.io_loop.start()\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 524, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in process_one\n      await dispatch(*args)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 418, in dispatch_shell\n      await result\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 758, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 426, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Federico\\AppData\\Local\\Temp\\ipykernel_4308\\2423064364.py\", line 10, in <module>\n      pred = predict_image(test_img_nsy, CBDNet)\n    File \"C:\\Users\\Federico\\AppData\\Local\\Temp\\ipykernel_4308\\4193731735.py\", line 6, in predict_image\n      pred_img = model.predict(img)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 2253, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function\n      return step_function(self, iterator)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step\n      outputs = model.predict_step(data)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n      return self(x, training=False)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 314, in call\n      return self.activation(outputs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\activations.py\", line 317, in relu\n      return backend.relu(\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\backend.py\", line 5366, in relu\n      x = tf.nn.relu(x)\nNode: 'model/conv2d_5/Relu'\nOOM when allocating tensor with shape[16,64,1024,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/conv2d_5/Relu}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_predict_function_5348]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Federico\\Documents\\Sviluppo\\Git\\PathTracing\\CNN-Denoiser\\CBDNet.ipynb Cella 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Federico/Documents/Sviluppo/Git/PathTracing/CNN-Denoiser/CBDNet.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m path \u001b[39m=\u001b[39m sample[\u001b[39m'\u001b[39m\u001b[39mNoisy Images\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Federico/Documents/Sviluppo/Git/PathTracing/CNN-Denoiser/CBDNet.ipynb#X21sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m test_img_nsy \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(path)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Federico/Documents/Sviluppo/Git/PathTracing/CNN-Denoiser/CBDNet.ipynb#X21sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m pred \u001b[39m=\u001b[39m predict_image(test_img_nsy, CBDNet)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Federico/Documents/Sviluppo/Git/PathTracing/CNN-Denoiser/CBDNet.ipynb#X21sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m pred \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mresize(pred, (\u001b[39m512\u001b[39m, \u001b[39m512\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Federico/Documents/Sviluppo/Git/PathTracing/CNN-Denoiser/CBDNet.ipynb#X21sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m test_img_nsy\u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(test_img_nsy, cv2\u001b[39m.\u001b[39mCOLOR_BGR2RGB)\n",
      "\u001b[1;32mc:\\Users\\Federico\\Documents\\Sviluppo\\Git\\PathTracing\\CNN-Denoiser\\CBDNet.ipynb Cella 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Federico/Documents/Sviluppo/Git/PathTracing/CNN-Denoiser/CBDNet.ipynb#X21sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         nsy\u001b[39m.\u001b[39mappend(img)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Federico/Documents/Sviluppo/Git/PathTracing/CNN-Denoiser/CBDNet.ipynb#X21sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m nsy \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(nsy)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Federico/Documents/Sviluppo/Git/PathTracing/CNN-Denoiser/CBDNet.ipynb#X21sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m pred_img \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(nsy)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Federico/Documents/Sviluppo/Git/PathTracing/CNN-Denoiser/CBDNet.ipynb#X21sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m pred_img \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mreshape(pred_img,(\u001b[39m4\u001b[39m,\u001b[39m4\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m256\u001b[39m,\u001b[39m256\u001b[39m,\u001b[39m3\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Federico/Documents/Sviluppo/Git/PathTracing/CNN-Denoiser/CBDNet.ipynb#X21sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m pred_img \u001b[39m=\u001b[39m unpatchify(pred_img, img\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model/conv2d_5/Relu' defined at (most recent call last):\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 737, in start\n      self.io_loop.start()\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 524, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in process_one\n      await dispatch(*args)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 418, in dispatch_shell\n      await result\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 758, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 426, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Federico\\AppData\\Local\\Temp\\ipykernel_4308\\2423064364.py\", line 10, in <module>\n      pred = predict_image(test_img_nsy, CBDNet)\n    File \"C:\\Users\\Federico\\AppData\\Local\\Temp\\ipykernel_4308\\4193731735.py\", line 6, in predict_image\n      pred_img = model.predict(img)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 2253, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function\n      return step_function(self, iterator)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step\n      outputs = model.predict_step(data)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n      return self(x, training=False)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 314, in call\n      return self.activation(outputs)\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\activations.py\", line 317, in relu\n      return backend.relu(\n    File \"c:\\Software\\Programs\\Conda\\envs\\tf\\lib\\site-packages\\keras\\backend.py\", line 5366, in relu\n      x = tf.nn.relu(x)\nNode: 'model/conv2d_5/Relu'\nOOM when allocating tensor with shape[16,64,1024,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/conv2d_5/Relu}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_predict_function_5348]"
     ]
    }
   ],
   "source": [
    "path = sample['Ground Truth Images'].iloc[0]\n",
    "test_img_gt = cv2.imread(path)\n",
    "test_img_gt = cv2.cvtColor(test_img_gt, cv2.COLOR_BGR2RGB)\n",
    "test_img_gt = cv2.resize(test_img_gt, (512, 512))\n",
    "test_img_gt = test_img_gt.astype(\"float32\") / 255.0\n",
    "\n",
    "path = sample['Noisy Images'].iloc[0]\n",
    "test_img_nsy = cv2.imread(path)\n",
    "\n",
    "pred = prediction(test_img_nsy, CBDNet)\n",
    "pred = cv2.resize(pred, (512, 512))\n",
    "\n",
    "test_img_nsy= cv2.cvtColor(test_img_nsy, cv2.COLOR_BGR2RGB)\n",
    "test_img_nsy = cv2.resize(test_img_nsy, (512, 512))\n",
    "test_img_nsy = test_img_nsy.astype(\"float32\") / 255.0\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(30,30))\n",
    "ax[0].imshow(test_img_nsy)\n",
    "ax[0].title.set_text('Noisy')\n",
    "ax[1].imshow(pred)\n",
    "ax[1].title.set_text('Pred')\n",
    "ax[2].imshow(test_img_gt)\n",
    "ax[2].title.set_text('GT')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras.export'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Federico\\Documents\\Sviluppo\\Git\\PathTracing\\CNN-Denoiser\\CBDNet.ipynb Cella 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Federico/Documents/Sviluppo/Git/PathTracing/CNN-Denoiser/CBDNet.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexport\u001b[39;00m \u001b[39mimport\u001b[39;00m ExportArchive\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Federico/Documents/Sviluppo/Git/PathTracing/CNN-Denoiser/CBDNet.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# CBDNet.export('models/exported/CBDNet')\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Federico/Documents/Sviluppo/Git/PathTracing/CNN-Denoiser/CBDNet.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m export_archive \u001b[39m=\u001b[39m ExportArchive()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.export'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.export import ExportArchive\n",
    "\n",
    "# CBDNet.export('models/exported/CBDNet')\n",
    "\n",
    "export_archive = ExportArchive()\n",
    "export_archive.track(CBDNet)\n",
    "export_archive.add_endpoint(\n",
    "    name='serve',\n",
    "    fn=CBDNet.call,\n",
    "    input_signature=[tf.TensorSpec(shape=(None, 3), dtype=tf.float32)],\n",
    ")\n",
    "\n",
    "export_archive.write_out('models/exported/CBDNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 24). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Federico\\AppData\\Local\\Temp\\tmp7ny1kgwp\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Federico\\AppData\\Local\\Temp\\tmp7ny1kgwp\\assets\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(CBDNet)\n",
    "light_model = converter.convert()\n",
    "\n",
    "with open('models/exported/CBDNet.tflite', 'wb') as f:\n",
    "    f.write(light_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
